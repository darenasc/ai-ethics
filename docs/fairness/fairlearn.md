# **[Fairlearn](https://fairlearn.github.io/)**

**Overall evaluation**

_Technical Implementation_

Useful: 4/5
Comprehensive: 4/5
Technical scalability: 5/5
Easy to customize (data): 5/5
Easy to customize (visualizations / analyses): 5/5
Easy to integrate: 5/5
Robustness: ?/5

_User-friendliness (system usability scale)_

Answer with strongly agree (5), agree (4), neutral (3), disagree (2), strongly disagree (1)

Feel free to add comments and justifications!

- I think that I would like to use this system frequently: 5, I feel it has more of what Iâ€™d need and it seems easy to integration
- I found the system unnecessarily complex: 1
- I thought the system was easy to use: 4 (-1 for missing documentation)
- I think that I would need the support of a technical person to be able to use this system: 3
- I found the various functions in this system were well integrated: 5, clustered in classes
- I thought there was too much inconsistency in this system: 1
- I would imagine that most people would learn to use this system very quickly: 3, needs more documentation and case studies
- I found the system very cumbersome to use: 1
- I felt very confident using the system: 4
- I needed to learn a lot of things before I could get going with this system: 1

## Description of the tool

Assess the fairness of their machine learning models and mitigate unfairness. It can assess existing models and train new models with fairness in mind. Compare models and make trade-offs between fairness and model performance.

Best for:

- Detection bias in binary classification model predictors and applying mitigation techniques

## Pros & cons

### Pros:

- Easy to install
- Includes dashboard to guide the user
- Includes several mitigation techniques
- It includes equalised odds among other fairness definitions

**Limitations, especially any technical issues**

- Lack of documentation on mitigation techniques
- There are examples, but no case studies going more in depth

## Case study demo with screenshots

Add in screenshots with descriptions on the data set used!

IMAGE NEEDED

![alt_text](../_media/image17.png "image_tooltip")

![alt_text](../_media/image18.png "image_tooltip")
